{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome!","title":"Home"},{"location":"#welcome","text":"","title":"Welcome!"},{"location":"aws-land/","text":"AWS Ubuntu 18.04 Get EC2 instance metadata curl http://169.254.169.254/latest/meta-data/","title":"AWS"},{"location":"aws-land/#aws","text":"","title":"AWS"},{"location":"aws-land/#ubuntu-1804","text":"Get EC2 instance metadata curl http://169.254.169.254/latest/meta-data/","title":"Ubuntu 18.04"},{"location":"cgroups/","text":"cgroups Ubuntu 18.04 view cgroup info of process via pid ps -o cgroup 12345 create memory cgroup sudo mkdir /sys/fs/cgroup/memory/cgroup-a limit memory of anything running in the cgroup cgroup-a to 4096 bytes echo 4096 | sudo tee /sys/fs/cgroup/memory/cgroup-a/memory.limit_in_bytes add process via pid to the cgroup cgroup-a sudo echo 12345 > /sys/fs/cgroup/memory/cgroup-a/cgroup.procs using libcgroup create memory cgroup cgroup-a sudo cgcreate -g memory:cgroup-a delete memory cgroup cgroup-a sudo cgdelete memory:cgroup-a run app app-a in cgroup cgroup-a sudo cgexec -g memory:cgroup-a app-a","title":"cgroups"},{"location":"cgroups/#cgroups","text":"","title":"cgroups"},{"location":"cgroups/#ubuntu-1804","text":"view cgroup info of process via pid ps -o cgroup 12345 create memory cgroup sudo mkdir /sys/fs/cgroup/memory/cgroup-a limit memory of anything running in the cgroup cgroup-a to 4096 bytes echo 4096 | sudo tee /sys/fs/cgroup/memory/cgroup-a/memory.limit_in_bytes add process via pid to the cgroup cgroup-a sudo echo 12345 > /sys/fs/cgroup/memory/cgroup-a/cgroup.procs","title":"Ubuntu 18.04"},{"location":"cgroups/#using-libcgroup","text":"create memory cgroup cgroup-a sudo cgcreate -g memory:cgroup-a delete memory cgroup cgroup-a sudo cgdelete memory:cgroup-a run app app-a in cgroup cgroup-a sudo cgexec -g memory:cgroup-a app-a","title":"using libcgroup"},{"location":"kubernetes/","text":"Kubernetes kubectl v1.12.2 General Practices use --context= to ensure correct context is targeted CLI setup env sudo ln -s $(which kubectl) /usr/bin/k resource short-names svc = service ds = daemonset po = pod deploy = deployment vs = virtualservice gw = gateway ksvc = knative service get resource YAML k get <resource-type> <resoruce-id> -n <namespace> -o yaml get the pods from a Deployment deployment=<deployment name> k get pod --selector=\"$(k describe deployments $deployment | grep Selector | awk '{print $2}')\" --output=wide delete Service and Deployment deployment=<deployment-id> namespace=<namespace> k delete services $(k get svc --selector=$(k describe deployments $deployment -n $namespace | grep Selector | awk '{print $2}') | sed -n 2p | awk '{print $1}') k delete deploy $deployment -n $namespace view all node taints k get nodes -o json | jq '.items[] | .metadata.name, .spec.taints' create busybox pod for troubleshooting k run -i --tty --rm debug --image=busybox --restart=Never -- sh restart all pods in a deployment/daemonset k get pods -n namespace | grep pod-name | cut -d \" \" -f1 - | xargs k delete pod -n namespace remove the CRD finalizer blocking k patch crd/crontabs.stable.example.com -p '{\"metadata\":{\"finalizers\":[]}}' --type=merge Istio verify mesh policy exists k get policies.authentication.istio.io --all-namespaces k get meshpolicies.authentication.istio.io get all istio destination rule hosts k get destinationrules.networking.istio.io --all-namespaces -o yaml | grep \"host:\" change envoy sidecare log level k -n easybake exec -it -c istio-proxy easybake-ui-6bd7f9bf-9pb5w -- curl -XPOST http://localhost:15000/logging?level=trace show given envoy configuration istioctl proxy-config clusters -n istio-system istio-ingressgateway-65576f8745-kbvgl -o json show routing for a port on a pod istioctl proxy-config listeners easybake-ui-6bd7f9bf-klhvx -n easybake --port 3800 -o json General Networking Flush iptables on a host systemctl stop docker.service iptables -F -t nat iptables -X -t nat iptables -F -t mangle iptables -X -t mangle iptables -F iptables -X systemctl start docker.service Weave Download the weave executable and place on k8s host. Make sure the version matches what is running in the cluster. Connection status between all hosts on the weave overlay network. If run on a healthy node the unhealthy node wont show up in the output. If run on an unhealthy node you will get no results ./weave status peers Connection from the host you are on to the other hosts in the k8s cluster on the weave overlay network. If run on a healthy node you will see connections that could not be established in the output if there is an unhealthy node. If run on an unhealthy node you will see all the connections fail. ./weave status connections","title":"Kubernetes"},{"location":"kubernetes/#kubernetes","text":"","title":"Kubernetes"},{"location":"kubernetes/#kubectl-v1122","text":"","title":"kubectl v1.12.2"},{"location":"kubernetes/#general-practices","text":"use --context= to ensure correct context is targeted","title":"General Practices"},{"location":"kubernetes/#cli","text":"setup env sudo ln -s $(which kubectl) /usr/bin/k resource short-names svc = service ds = daemonset po = pod deploy = deployment vs = virtualservice gw = gateway ksvc = knative service get resource YAML k get <resource-type> <resoruce-id> -n <namespace> -o yaml get the pods from a Deployment deployment=<deployment name> k get pod --selector=\"$(k describe deployments $deployment | grep Selector | awk '{print $2}')\" --output=wide delete Service and Deployment deployment=<deployment-id> namespace=<namespace> k delete services $(k get svc --selector=$(k describe deployments $deployment -n $namespace | grep Selector | awk '{print $2}') | sed -n 2p | awk '{print $1}') k delete deploy $deployment -n $namespace view all node taints k get nodes -o json | jq '.items[] | .metadata.name, .spec.taints' create busybox pod for troubleshooting k run -i --tty --rm debug --image=busybox --restart=Never -- sh restart all pods in a deployment/daemonset k get pods -n namespace | grep pod-name | cut -d \" \" -f1 - | xargs k delete pod -n namespace remove the CRD finalizer blocking k patch crd/crontabs.stable.example.com -p '{\"metadata\":{\"finalizers\":[]}}' --type=merge","title":"CLI"},{"location":"kubernetes/#istio","text":"verify mesh policy exists k get policies.authentication.istio.io --all-namespaces k get meshpolicies.authentication.istio.io get all istio destination rule hosts k get destinationrules.networking.istio.io --all-namespaces -o yaml | grep \"host:\" change envoy sidecare log level k -n easybake exec -it -c istio-proxy easybake-ui-6bd7f9bf-9pb5w -- curl -XPOST http://localhost:15000/logging?level=trace show given envoy configuration istioctl proxy-config clusters -n istio-system istio-ingressgateway-65576f8745-kbvgl -o json show routing for a port on a pod istioctl proxy-config listeners easybake-ui-6bd7f9bf-klhvx -n easybake --port 3800 -o json","title":"Istio"},{"location":"kubernetes/#general-networking","text":"Flush iptables on a host systemctl stop docker.service iptables -F -t nat iptables -X -t nat iptables -F -t mangle iptables -X -t mangle iptables -F iptables -X systemctl start docker.service","title":"General Networking"},{"location":"kubernetes/#weave","text":"Download the weave executable and place on k8s host. Make sure the version matches what is running in the cluster. Connection status between all hosts on the weave overlay network. If run on a healthy node the unhealthy node wont show up in the output. If run on an unhealthy node you will get no results ./weave status peers Connection from the host you are on to the other hosts in the k8s cluster on the weave overlay network. If run on a healthy node you will see connections that could not be established in the output if there is an unhealthy node. If run on an unhealthy node you will see all the connections fail. ./weave status connections","title":"Weave"},{"location":"linux-system-calls/","text":"Linux System Calls seccomp (secure computing mode) Filter system calls issued by a program. The filters are based on BPF (Berkley Packet Filters). The idea behind seccomp is to restrict the system calls that can be made from a process, he said. The Linux kernel has a few hundred system calls, but most of them are not needed by any given process. If a process can be compromised and tricked into making other system calls, though, it may lead to a security vulnerability that could result in the compromise of the whole system. By restricting what system calls can be made, seccomp is a key component for building application sandboxes. #include <seccomp.h> /* libseccomp */ scmp_filter_ctx ctx; ctx = seccomp_init(SCMP_ACT_KILL); // default action: kill seccomp_rule_add(ctx, SCMP_ACT_ALLOW, SCMP_SYS(dup2), 2, SCMP_A0(SCMP_CMP_EQ, 1), SCMP_A1(SCMP_CMP_EQ, 2)); // pass dup2(1,2); //fail dup2(2, 42); dup2 Change file descriptor. // redirect stderr to stdout dup2(1, 2); prlimit Get and set process resource limits. This routine makes ULIMIT(3) obsolete. struct rlimit old, new; struct rlimit *newp; pid_t pid; new.rlim_cur = /* soft limit */ new.rlim_max = /* hard limit */ newp = &new; prlimit(pid, RLIMIT_CPU, newp, &old) /* resource options in PRLIMIT(2) */ There is also a CLI tool for prlimit in PRLIMIT(1). printk Logging mechanism for debugging kernel space code. #include <linux/kernel.h> /* Needed for KERN_ALERT */ printk(\"<0>System dead.\\n\"); from userspace $ echo \"2Writing critical printk messages from userspace\" >/dev/kmsg $ dmesg console_loglevel To determine current console_loglevel: $ cat /proc/sys/kernel/printk The output values are in respect: current default minimum boot-time-default","title":"Linux System Calls"},{"location":"linux-system-calls/#linux-system-calls","text":"","title":"Linux System Calls"},{"location":"linux-system-calls/#seccomp-secure-computing-mode","text":"Filter system calls issued by a program. The filters are based on BPF (Berkley Packet Filters). The idea behind seccomp is to restrict the system calls that can be made from a process, he said. The Linux kernel has a few hundred system calls, but most of them are not needed by any given process. If a process can be compromised and tricked into making other system calls, though, it may lead to a security vulnerability that could result in the compromise of the whole system. By restricting what system calls can be made, seccomp is a key component for building application sandboxes. #include <seccomp.h> /* libseccomp */ scmp_filter_ctx ctx; ctx = seccomp_init(SCMP_ACT_KILL); // default action: kill seccomp_rule_add(ctx, SCMP_ACT_ALLOW, SCMP_SYS(dup2), 2, SCMP_A0(SCMP_CMP_EQ, 1), SCMP_A1(SCMP_CMP_EQ, 2)); // pass dup2(1,2); //fail dup2(2, 42);","title":"seccomp (secure computing mode)"},{"location":"linux-system-calls/#dup2","text":"Change file descriptor. // redirect stderr to stdout dup2(1, 2);","title":"dup2"},{"location":"linux-system-calls/#prlimit","text":"Get and set process resource limits. This routine makes ULIMIT(3) obsolete. struct rlimit old, new; struct rlimit *newp; pid_t pid; new.rlim_cur = /* soft limit */ new.rlim_max = /* hard limit */ newp = &new; prlimit(pid, RLIMIT_CPU, newp, &old) /* resource options in PRLIMIT(2) */ There is also a CLI tool for prlimit in PRLIMIT(1).","title":"prlimit"},{"location":"linux-system-calls/#printk","text":"Logging mechanism for debugging kernel space code. #include <linux/kernel.h> /* Needed for KERN_ALERT */ printk(\"<0>System dead.\\n\");","title":"printk"},{"location":"linux-system-calls/#from-userspace","text":"$ echo \"2Writing critical printk messages from userspace\" >/dev/kmsg $ dmesg","title":"from userspace"},{"location":"linux-system-calls/#console_loglevel","text":"To determine current console_loglevel: $ cat /proc/sys/kernel/printk The output values are in respect: current default minimum boot-time-default","title":"console_loglevel"}]}